[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math for Data Science",
    "section": "",
    "text": "üëã Welcome to the official landing page for Math for Data Science! This site is designed to help you learn essential math concepts for your data science journey at The George Washington University.\n\n\n\n\n\n\n\n  \n    \n    Probability\n  \n\n  \n    \n    Linear Algebra\n    Coming Soon... ‚è≥ \n  \n\n  \n    \n    Calculus\n    Coming Soon... ‚è≥ \n  \n\n  \n    \n    Statistics\n    Coming Soon... ‚è≥"
  },
  {
    "objectID": "content/probability/07-prob-dist.html",
    "href": "content/probability/07-prob-dist.html",
    "title": "Probability Distributions",
    "section": "",
    "text": "A function that assigns probabilities to outcomes, defining the overall behavior of a random process. ü§ì",
    "crumbs": [
      "Probability",
      "Probability Distributions"
    ]
  },
  {
    "objectID": "content/probability/07-prob-dist.html#bernoulli-distribution",
    "href": "content/probability/07-prob-dist.html#bernoulli-distribution",
    "title": "Probability Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\\[\np_{X}(x) =\n\\begin{cases}\n    p & \\text{if } x = 1, \\\\\n    q = 1-p & \\text{if } x = 0.\n\\end{cases}\n\\]\n\nThe discrete random variable can take value \\(1\\) with probability \\(p\\) or value \\(0\\) with probability \\(q = 1 - p\\)\nNot to be confused with the binomial distribution, since only one trial is being conducted.\n\\(\\mathbb{E}[X] = p\\)\n\\(Var[X] = pq\\) \n\n\n\nviewof p = Inputs.range([0, 1], {\n  step: 0.01,\n  value: 0.5,\n  label: tex`p`,\n  width: 200\n})\n\ndata = {\n  return [\n    {outcome: \"0\", probability: 1 - p},\n    {outcome: \"1\", probability: p}\n  ];\n}\n\nPlot.plot({\n  style: \"overflow: visible; display: block; margin: 0 auto;\",\n  width: 600,\n  height: 400,\n  y: {\n    grid: true,\n    label: \"Probability\",\n    domain: [0, 1]\n  },\n  x: {\n    label: \"Outcome\",\n    padding: 0.2\n  },\n  marks: [\n    Plot.barY(data, {\n      x: \"outcome\",\n      y: \"probability\",\n      fill: \"steelblue\"\n    }),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"text-align: center; margin-top: 1em;\"&gt;\n  &lt;p&gt;${tex`\\mathbb{E}[X] =`} ${p.toFixed(3)}&lt;/p&gt;\n  &lt;p&gt;${tex`\\text{Var}(X) =`} ${(p * (1-p)).toFixed(3)}&lt;/p&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nPython Code: Bernoulli Distribution\nTo create Bernoulli distributed data using numpy:\nimport numpy as np\n\ninterval = [0,1]\nsize = (1000,1)\np = [1-0.5, 0.5]\n\ndata = np.random.choice(interval, size, p = p)",
    "crumbs": [
      "Probability",
      "Probability Distributions"
    ]
  },
  {
    "objectID": "content/probability/07-prob-dist.html#gaussian-distribution",
    "href": "content/probability/07-prob-dist.html#gaussian-distribution",
    "title": "Probability Distributions",
    "section": "Gaussian Distribution",
    "text": "Gaussian Distribution\n\\[\nf_{X}(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2} }}e^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}}\n\\]\n\nUsed frequently to represent real-valued random variables whose distributions are not known.\nIts importance is derived from the central limit theorem that states, under some conditions, the average of many samples of a random variable is itself a random variable that converges to a Gaussian distribution as it increases.\n\\(E[X] = \\mu\\)\n\\(Var[X] = \\sigma^{2}\\)\n\n\n\nviewof mu = Inputs.range([-1, 1], {\n  step: 0.1,\n  value: 0,\n  label: tex`\\mu`,\n  width: 200\n})\n\nviewof sigma = Inputs.range([0.1, 2], {\n  step: 0.1,\n  value: 1,\n  label: tex`\\sigma`,\n  width: 200\n})\n\n// Generate points for the normal distribution curve\npointsGaussian = {\n  const x = d3.range(-5, 5, 0.1);\n  return x.map(x =&gt; ({\n    x,\n    y: (1 / (sigma * Math.sqrt(2 * Math.PI))) * \n       Math.exp(-0.5 * Math.pow((x - mu) / sigma, 2))\n  }));\n}\n\nPlot.plot({\n  style: \"overflow: visible; display: block; margin: 0 auto;\",\n  width: 600,\n  height: 400,\n  y: {\n    grid: true,\n    label: \"Density\"\n  },\n  x: {\n    label: \"x\",\n    domain: [-5, 5]\n  },\n  marks: [\n    Plot.line(pointsGaussian, {x: \"x\", y: \"y\", stroke: \"steelblue\"}),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"text-align: center; margin-top: 1em;\"&gt;\n  &lt;p&gt;${tex`\\mathbb{E}[X] =`} ${mu.toFixed(3)}&lt;/p&gt;\n  &lt;p&gt;${tex`\\text{Var}(X) =`} ${(sigma * sigma).toFixed(3)}&lt;/p&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nPython Code: Gaussian Distribution\nTo create Gaussian distributed data using numpy:\nimport numpy as np\n\nmu = 0\nsigma = 1\nsize = (1000,1)\n\ndata = np.random.normal(mu, sigma, size)",
    "crumbs": [
      "Probability",
      "Probability Distributions"
    ]
  },
  {
    "objectID": "content/probability/07-prob-dist.html#beta-distribution",
    "href": "content/probability/07-prob-dist.html#beta-distribution",
    "title": "Probability Distributions",
    "section": "Beta Distribution",
    "text": "Beta Distribution\n\\[\nf_{X}(x) = {\\frac {\\Gamma (\\alpha +\\beta )}{\\Gamma (\\alpha )\\Gamma (\\beta )}}\\,x^{\\alpha -1}(1-x)^{\\beta -1}\n\\]\nwhere \\(\\Gamma\\) is the gamma function defined as:\n\\[\n\\Gamma (z)=\\int _{0}^{\\infty}t^{z-1}e^{-t}\\,dt\n\\]\n\nGamma functions are used to model factorial functions of complex numbers \\(z\\).\nBeta functions are used to model behavior of random variables in intervals of finite length.\n\\(E[X] = \\frac{\\alpha}{\\alpha+\\beta}\\)\n\\(Var[X] = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\\)\n\n\n\nviewof alpha = Inputs.range([0.1, 10], {\n  step: 0.1,\n  value: 1,\n  label: tex`\\alpha`,\n  width: 200\n})\n\nviewof beta = Inputs.range([0.1, 10], {\n  step: 0.1,\n  value: 1,\n  label: tex`\\beta`,\n  width: 200\n})\n\n// Gamma function approximation using Lanczos approximation\nfunction gamma(z) {\n    const p = [676.5203681218851, -1259.1392167224028, 771.32342877765313,\n        -176.61502916214059, 12.507343278686905, -0.13857109526572012,\n        9.9843695780195716e-6, 1.5056327351493116e-7];\n    \n    if (z &lt; 0.5) {\n        return Math.PI / (Math.sin(Math.PI * z) * gamma(1 - z));\n    }\n    \n    z -= 1;\n    let x = 0.99999999999980993;\n    for (let i = 0; i &lt; p.length; i++) {\n        x += p[i] / (z + i + 1);\n    }\n    \n    const t = z + p.length - 0.5;\n    return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;\n}\n\n// Beta function using gamma function\nfunction betaFunc(x, y) {\n    return (gamma(x) * gamma(y)) / gamma(x + y);\n}\n\n// Beta probability density function\nfunction betaPDF(x, a, b) {\n    if (x &lt;= 0 || x &gt;= 1) return 0;\n    return Math.pow(x, a - 1) * Math.pow(1 - x, b - 1) / betaFunc(a, b);\n}\n\n// Generate points for the beta distribution curve\npoints = Array.from({length: 100}, (_, i) =&gt; {\n  let x = 0.001 + i * 0.01;\n  return { x, y: betaPDF(x, alpha, beta) };\n});\n\nPlot.plot({\n  style: \"overflow: visible; display: block; margin: 0 auto;\",\n  width: 600,\n  height: 400,\n  y: {\n    grid: true,\n    label: \"Density\"\n  },\n  x: {\n    label: \"x\",\n    domain: [0, 1]\n  },\n  marks: [\n    Plot.line(points, {x: \"x\", y: \"y\", stroke: \"steelblue\"}),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"text-align: center; margin-top: 1em;\"&gt;\n  &lt;p&gt;${tex`\\mathbb{E}[X] =`} ${(alpha/(alpha + beta)).toFixed(3)}&lt;/p&gt;\n  &lt;p&gt;${tex`\\text{Var}(X) =`} ${((alpha * beta)/((alpha + beta)**2 * (alpha + beta + 1))).toFixed(3)}&lt;/p&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nPython Code: Beta Distribution\nTo create Beta distributed data using numpy:\nimport numpy as np \n\nalpha = 0.5\nbeta = 0.5\nsize = (1000,1)\n\ndata = np.random.beta(alpha, beta, size)",
    "crumbs": [
      "Probability",
      "Probability Distributions"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html",
    "href": "content/probability/05-discrete-rv.html",
    "title": "Discrete Random Variables",
    "section": "",
    "text": "A type of variable that takes distinct, countable values, often used to model finite outcomes. üìä",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#discrete-random-variable",
    "href": "content/probability/05-discrete-rv.html#discrete-random-variable",
    "title": "Discrete Random Variables",
    "section": "Discrete Random Variable",
    "text": "Discrete Random Variable\nA discrete random variable is a mapping \\(X\\) of all of the outcomes of a sample space to numerical values \\(x \\in \\mathbb{Z}\\).\n\\[\nX: Outcome \\in Sample \\ Space \\to x \\in \\mathbb{Z}\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#probability-mass-function-pmf",
    "href": "content/probability/05-discrete-rv.html#probability-mass-function-pmf",
    "title": "Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nA probability mass function (PMF) is a mapping of values \\(x\\) of discrete random variables \\(X\\) to probabilities \\([0,1]\\).\n\\[\np_{X}(x) = P(X = x)\n\\]\nPMF has properties: \\[\np_{X}(x) \\geq 0, \\quad \\sum_{x} p_{X}(x) = 1\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#cumulative-distribution-function-cdf",
    "href": "content/probability/05-discrete-rv.html#cumulative-distribution-function-cdf",
    "title": "Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nThe cumulative distribution function (CDF) for discrete random variables is defined as:\n\\[\nF_{X}(x) = P(X \\leq x) = \\sum_{k \\leq x} p_{X}(k)\n\\]\nRelation to PMF: \\[\np_{X}(x) = \\frac{dF_{X}(x)}{dx}\n\\]\n\\[\nF_{X}(x) = \\sum_{k \\leq x}p_{X}(k)\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#illustration-pmf-and-cdf",
    "href": "content/probability/05-discrete-rv.html#illustration-pmf-and-cdf",
    "title": "Discrete Random Variables",
    "section": "Illustration: PMF and CDF",
    "text": "Illustration: PMF and CDF",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#expectation-and-variance-of-pmfs",
    "href": "content/probability/05-discrete-rv.html#expectation-and-variance-of-pmfs",
    "title": "Discrete Random Variables",
    "section": "Expectation and Variance of PMFs",
    "text": "Expectation and Variance of PMFs\nDiscrete expectation, or mean, is the average numerical value that the discrete random variable takes over the PMF. \\[\nE[X] = \\sum_{x} x \\ p_{X}(x)\n\\]\nDiscrete variance is the expected squared difference from the mean of a PMF. \\[\nVar[X] = E[(X - E[X])^{2}] = \\sum_{x}(x - E[X])^2 p_{X}(x)\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#joint-and-marginal-pmfs",
    "href": "content/probability/05-discrete-rv.html#joint-and-marginal-pmfs",
    "title": "Discrete Random Variables",
    "section": "Joint and Marginal PMFs",
    "text": "Joint and Marginal PMFs\nThe joint PMF calculates the intersection of two discrete random variables: \\[\np_{X,Y}(x_{1},x_{2}) = P(X = x_{1}, Y = x_{2})\n\\]\nFrom the previous definition we can also compute the marginal PMF for a particular random variable: \\[\np_{X}(x_{1}) = \\sum_{x_{2}} p_{X,Y}(X = x_{1},Y = x_{2})\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#conditional-expectation-of-pmfs",
    "href": "content/probability/05-discrete-rv.html#conditional-expectation-of-pmfs",
    "title": "Discrete Random Variables",
    "section": "Conditional Expectation of PMFs",
    "text": "Conditional Expectation of PMFs\nThe conditional PMF gives the probability distribution of a discrete random variable given that another variable has a specific value. \\[\np_{X|Y}(x_{1}| x_{2}) = \\frac{p_{X,Y}(x_{1}, x_{2})}{p_{Y}(x_{2})}\n\\]\nThe conditional expectation is the expected value of a discrete random variable given that another variable is fixed at a specific value. \\[\nE[X| Y = x_{2}] = \\sum_{x_{1}} x_{1} \\frac{p_{X,Y}(x_{1}, x_{2})}{p_{Y}(x_{2})}\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/05-discrete-rv.html#independence",
    "href": "content/probability/05-discrete-rv.html#independence",
    "title": "Discrete Random Variables",
    "section": "Independence",
    "text": "Independence\nTwo discrete random variables are independent if:\n\\[\np_{X,Y}(x_{1}, x_{2}) = p_{X}(x_{1}) p_{Y}(x_{2})\n\\]\nFor multiple discrete random variables: \\[\np_{X_{1},...,X_{n}}(x_{1}, ..., x_{n}) = p_{X_{1}}(x_{1}) ... \\ p_{X_{n}}(x_{n})\n\\]",
    "crumbs": [
      "Probability",
      "Discrete Random Variables"
    ]
  },
  {
    "objectID": "content/probability/03-conditioning.html",
    "href": "content/probability/03-conditioning.html",
    "title": "Conditioning",
    "section": "",
    "text": "A way to update probabilities when given new information, refining our understanding of how likely an event is. ü§î",
    "crumbs": [
      "Probability",
      "Conditioning"
    ]
  },
  {
    "objectID": "content/probability/03-conditioning.html#conditional-probability",
    "href": "content/probability/03-conditioning.html#conditional-probability",
    "title": "Conditioning",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nSuppose \\(A\\) and \\(B\\) are events.  Conditional probability is the likelihood of an event occurring given that we know another event has occurred.\n\n\n\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nIntuition: conditioned event becomes the new sample space.  If \\(P(B) \\neq 0\\), then the probability of the intersection normalized by the conditioned space.  Else \\(P(B) = 0\\), then \\(P(A|B)\\) is undefined.",
    "crumbs": [
      "Probability",
      "Conditioning"
    ]
  },
  {
    "objectID": "content/probability/03-conditioning.html#product-rule",
    "href": "content/probability/03-conditioning.html#product-rule",
    "title": "Conditioning",
    "section": "Product Rule",
    "text": "Product Rule\nSuppose \\(A\\) and \\(B\\) are events.  The product rule states that the probability of two events \\(A\\) and \\(B\\) occurring together \\(A \\cap B\\) is given by the probability of one event occurring given the other \\(P(A|B)\\) or \\(P(B|A)\\) multiplied by the probability of the other event.\n\\[\nP(A \\cap B) = P(A|B) P(B) = P(B|A) P(A)\n\\]",
    "crumbs": [
      "Probability",
      "Conditioning"
    ]
  },
  {
    "objectID": "content/probability/03-conditioning.html#total-probability-theorem",
    "href": "content/probability/03-conditioning.html#total-probability-theorem",
    "title": "Conditioning",
    "section": "Total Probability Theorem",
    "text": "Total Probability Theorem\nSuppose \\(A_{1,...,n}\\) and \\(B\\) are sets.  The total probability theorem allows us to compute the likelihood of an event by summing over conditional probabilities of different partitions of the sample space.\n\\[\nP(B) = P(B|A_1) P(A_1) + P(B|A_2) P(A_2) + P(B|A_3) P(A_3)\n\\]\n\n\n\nIn general terms:\n\\[\nP(B) = P(B|A_1) P(A_1) + ... + P(B|A_n) P(A_n)\n\\]\n\nExercise\nExperiment: Classifying emails as spam \\(S\\) or not spam \\(NS\\) based on the word \\(W\\) or not the word \\(NW\\) ‚Äúfree‚Äù.\n\\[\nP(S) = 0.4\n\\]\n\\[\nP(NS) = 0.6\n\\]\n\\[\nP(W|S) = 0.7\n\\]\n\\[\nP(W|NS) = 0.1\n\\]\nFind the probability of \\(P(S|W)\\):\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\nP(S|W) = \\frac{P(S \\cap W)}{P(W)} = \\underbrace{\\frac{P(W|S)P(S)}{P(W|S)P(S) + P(W|NS)P(NS)}}_{Bayes' \\ Theorem} = \\frac{0.7 * 0.4}{0.7 * 0.4 + 0.1 * 0.6} = 0.82\n\\]",
    "crumbs": [
      "Probability",
      "Conditioning"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html",
    "href": "content/probability/01-set-theory.html",
    "title": "Set Theory",
    "section": "",
    "text": "The study of collections of objects, where elements either belong to a set or they don‚Äôt‚Äîsimple, yet powerful! üåç",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html#sets",
    "href": "content/probability/01-set-theory.html#sets",
    "title": "Set Theory",
    "section": "Sets",
    "text": "Sets\nA set is a collection of things.  The things are called elements of a set.\n\\[\nColors = \\{Red, Blue, Green\\}\n\\]\n\\[\nNumbers = \\{1,2,3\\}\n\\]\nSets can be finite or infinite.\n\\[\nSome\\ Even\\ Integers = \\{2,4,6\\}\n\\]\n\\[\nAll\\ Even\\ Integers = \\{..., -4, -2, 0, 2, 4, ...\\}\n\\]\nThe number of elements in a set is called the cardinality.\n\\[\n|Colors| = 3\n\\]\nTwo sets are equal if they share exactly the same elements.\n\\[\nA = \\{2,4,6\\}, B = \\{4,2,6\\}, C = \\{4,2,7\\}\n\\]\n\\[\nA = B\n\\] \\[\nA \\neq C\n\\]\nTo express that \\(2\\) is an element of \\(A\\), we denote:\n\\[\n2 \\in A\n\\] \\[\n\\text{2 exists in A}\n\\]\n\\[\n5 \\notin A\n\\] \\[\n\\text{5 does not exist in A}\n\\]\nSome sets are so significant that we reserve special symbols for them:\n\\[\n\\emptyset = \\{\\} \\quad \\textbf{(empty set)}\n\\]\n\\[\n\\mathbb{N} = \\{1, 2, 3, ... \\} \\quad \\textbf{(natural numbers)}\n\\]\n\\[\n\\mathbb{Z} = \\{..., -2, -1, 0, 1, 2, ... \\} \\quad \\textbf{(integers)}\n\\]\n\\[\n\\mathbb{R} = \\{..., -0.22,...,0,...,1,..., \\pi, ... \\} \\quad \\textbf{(real numbers)}\n\\]\nWe visualize \\(\\mathbb{R}\\) as an infinitely long number line.",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html#set-builder-notation",
    "href": "content/probability/01-set-theory.html#set-builder-notation",
    "title": "Set Theory",
    "section": "Set-Builder Notation",
    "text": "Set-Builder Notation\nA special notation called set-builder notation is used to describe sets that are too big or complex to list between braces.\n\\[\nAll\\ Even\\ Integers_{1} = \\{..., -4, -2, 0, 2, 4, ...\\}\n\\]\n\\[\nAll\\ Even\\ Integers_{2} = \\{2x: x \\in \\mathbb{Z} \\}\n\\]\n\\[\n\\text{The set of all numbers of the form } 2x \\text{ such that } x \\in \\mathbb{Z}\n\\]\n\\[\nAll\\ Even\\ Integers_{1} = All\\ Even\\ Integers_{2}\n\\]\n\nExercise\nWrite the following sets in set-builder notation:\n\n\\(\\{ 2, 4, 8, 16, 32, 64, ... \\}\\)\n\\(\\{ 0, 1, 4, 9, 16, 25, 36, ... \\}\\)\n\\(\\{ 3, 4, 5, 6, 7, 8 \\}\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(\\{ 2^x: x \\in \\mathbb{N} \\}\\)\n\\(\\{ x^2: x \\in \\mathbb{Z} \\}\\)\n\\(\\{ x \\in \\mathbb{Z}: 3 \\le x \\le 8 \\}\\)",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html#subsets",
    "href": "content/probability/01-set-theory.html#subsets",
    "title": "Set Theory",
    "section": "Subsets",
    "text": "Subsets\nSuppose \\(A\\) and \\(B\\) are sets.  If every element of \\(A\\) is also an element of \\(B\\), then we say \\(A\\) is a subset of \\(B\\), denoted \\(A \\subseteq B\\).  We write \\(A \\not\\subseteq B\\) if \\(A\\) is not a subset of \\(B\\), that is, if it is not true that every element of \\(A\\) is also an element of \\(B\\). Thus \\(A \\not\\subseteq B\\) means that there is at least one element of \\(A\\) that is not an element of \\(B\\).\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{R}\n\\]\n\\[\nA = \\{1,2\\}, B = \\{2,3,4\\}\n\\] \\[\nA \\not\\subseteq B\n\\]\n\nExercise\nList all the subsets of the following sets:\n\n\\(\\{1,2,3\\}\\)\n\\(\\{1,\\{2,3\\}\\}\\)\n\\(\\{\\mathbb{N}, \\mathbb{Z}, \\mathbb{R}\\}\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(\\{\\}, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\)\n\\(\\{\\}, \\{1\\}, \\{\\{2,3\\}\\}, \\{1,\\{2,3\\}\\}\\)\n\\(\\{\\}, \\{\\mathbb{N}\\}, \\{\\mathbb{Z}\\}, \\{\\mathbb{R}\\}, \\{\\mathbb{N},\\mathbb{Z}\\}, \\{\\mathbb{N},\\mathbb{R}\\}, \\{\\mathbb{Z},\\mathbb{R}\\}, \\{\\mathbb{N},\\mathbb{Z},\\mathbb{R}\\}\\)",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html#union-intersection-and-difference",
    "href": "content/probability/01-set-theory.html#union-intersection-and-difference",
    "title": "Set Theory",
    "section": "Union, Intersection, and Difference",
    "text": "Union, Intersection, and Difference\nSuppose \\(A\\) and \\(B\\) are sets.\nA union of \\(A\\) and \\(B\\) is the set: \\[\nA \\cup B = \\{x: x \\in A \\text{ or } x \\in B \\}\n\\]\nA intersection of \\(A\\) and \\(B\\) is the set: \\[\nA \\cap B = \\{x: x \\in A \\text{ and } x \\in B \\}\n\\]\nA difference of \\(A\\) and \\(B\\) is the set: \\[\nA - B = \\{x: x \\in A \\text{ and } x \\notin B \\}\n\\]\n\n\n\n\nExercise\nShade in the region matching the expression:\n\n\\((A \\cap B) \\cap C\\)\n\\((A \\cup B) \\cap C\\)\n\\((A \\cup B) - C\\)\n\n\n\n\n\n\n\n\n\n\nSolution",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/01-set-theory.html#complements",
    "href": "content/probability/01-set-theory.html#complements",
    "title": "Set Theory",
    "section": "Complements",
    "text": "Complements\nSuppose \\(A\\) is a set.  A universal set is a larger set that encompasses other sets.  The complement of \\(A\\), denoted \\(\\bar{A}\\), is the set \\(\\bar{A} = U - A\\).\n\\[\nP = \\{2, 3, 5, 7, ...\\} \\quad \\textbf{(prime numbers)}\n\\]\n\\[\n\\bar{P} = \\mathbb{N} - P = \\{1, 4, 6, ...\\}\n\\]\n\nExercise\nFind \\(\\bar{A}\\):\n\\[\nA = \\{1,2,3\\}, U = \\{0,1,2,3,4,5\\}\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\bar{A} = \\{0, 4, 5\\}\n\\]",
    "crumbs": [
      "Probability",
      "Set Theory"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html",
    "href": "content/probability/02-axiomatic.html",
    "title": "Axiomatic Probability",
    "section": "",
    "text": "A formal framework that defines probability using three fundamental rules, ensuring consistency in measuring uncertainty. üé≤",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#methodology",
    "href": "content/probability/02-axiomatic.html#methodology",
    "title": "Axiomatic Probability",
    "section": "Methodology",
    "text": "Methodology\nSteps to perform a probabilistic model:\n\nSpecify sample space.\nDefine probability law (must align with probability axioms).\nIdentify event of interest.\nCalculate‚Ä¶",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#sample-space",
    "href": "content/probability/02-axiomatic.html#sample-space",
    "title": "Axiomatic Probability",
    "section": "Sample Space",
    "text": "Sample Space\nA sample space is a set of all possible outcomes from an experiment. \n\\[\nSample \\ Space = \\{Heads, Tails\\}\n\\]\nAn experiment is any procedure that can be repeated and has a well-defined set of outcomes. \n\\[\nFlipping \\ a \\ fair \\ coin\n\\]\nAn outcome is the end result of an experiment, or an element in the sample space.\n\\[\nHeads  \n\\]",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#illustration-discrete-sample-space",
    "href": "content/probability/02-axiomatic.html#illustration-discrete-sample-space",
    "title": "Axiomatic Probability",
    "section": "Illustration: Discrete Sample Space",
    "text": "Illustration: Discrete Sample Space\nExperiment: Rolling two fair die at the same time.\n\\[\nSample \\ Space = \\{ (x, y) : x,y \\in \\mathbb{N}, 1 \\leq x, y \\leq 6  \\}\n\\]",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#illustration-continuous-sample-space",
    "href": "content/probability/02-axiomatic.html#illustration-continuous-sample-space",
    "title": "Axiomatic Probability",
    "section": "Illustration: Continuous Sample Space",
    "text": "Illustration: Continuous Sample Space\nExperiment: Measure two continuous variables in the range \\([0,1]\\)\n\\[ Sample\\ Space = \\{ (x, y) : x,y \\in \\mathbb{R}, 0 \\leq x, y \\leq 1  \\} \\]",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#events-and-experiment",
    "href": "content/probability/02-axiomatic.html#events-and-experiment",
    "title": "Axiomatic Probability",
    "section": "Events and Experiment",
    "text": "Events and Experiment\nAn event is a subset of the sample space.  Events are important because they ultimately get assigned probabilities.\nExperiment: Rolling a die once.\n\\[\nSample \\ Space = \\{1,2,3,4,5,6\\}\n\\]\nWhat is the event of rolling a \\(1\\)?\n\\[\n\\{1\\} \\subseteq \\{1,2,3,4,5,6\\}\n\\]\nWhat is the event of rolling an odd number?\n\\[\n\\{1, 3, 5\\} \\subseteq \\{1,2,3,4,5,6\\}\n\\]",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/02-axiomatic.html#probability-axioms-and-probability-law",
    "href": "content/probability/02-axiomatic.html#probability-axioms-and-probability-law",
    "title": "Axiomatic Probability",
    "section": "Probability Axioms and Probability Law",
    "text": "Probability Axioms and Probability Law\nKolmogorov probability axioms are the foundations of axiomatic probability theory:\n\nNonnegativity: \\(P(Event) \\geq 0\\)\nNormalization: \\(P(Sample\\ Space) = 1\\)\nAdditivity: If \\(A \\cap B = \\emptyset, P(A \\cup B) = P(A) + P(B)\\)\n\nProbability laws are additional axioms mathematically derived from Kolmogorov probability axioms.\n\nExercise\nExperiment: Rolling two fair die at the same time.\nLet all outcomes be equally likely.\n\\[\nP(A) = \\frac{|A|}{|Sample\\ Space|}\n\\]\n\n\n\nFind the following probabilities:\n\n\\(P(die_1 = 1)\\)\n\\(P(max(die_1, die_2) = 2)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(P(die_1 = 1) = \\frac{6}{36} \\approx 0.1\\bar{6}\\)\n\\(P(max(die_1, die_2) = 2) = \\frac{2}{36} \\approx 0.0\\bar{5}\\)\n\n\n\n\n\n\nExercise\nExperiment: Measure two continuous variables in the range \\([0,1]\\)\n\\[\nSample\\ Space = \\{ (x, y) : x,y \\in \\mathbb{R}, 0 \\leq x, y \\leq 1  \\}\n\\]\n\n\n\nFind the following probabilities:\n\n\\(P(x = 0.5 , y = 0.5)\\)\n\\(P(x+y \\geq 1)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(P(x = 0.5 , y = 0.5) = 0\\)\n\\(P(x+y \\geq 1) = 0.5\\)",
    "crumbs": [
      "Probability",
      "Axiomatic Probability"
    ]
  },
  {
    "objectID": "content/probability/04-independence.html",
    "href": "content/probability/04-independence.html",
    "title": "Independence",
    "section": "",
    "text": "A property where two events do not influence each other, meaning the occurrence of one tells us nothing about the other. üîó",
    "crumbs": [
      "Probability",
      "Independence"
    ]
  },
  {
    "objectID": "content/probability/04-independence.html#independent-events",
    "href": "content/probability/04-independence.html#independent-events",
    "title": "Independence",
    "section": "Independent Events",
    "text": "Independent Events\nSuppose \\(A\\) and \\(B\\) are two events.  Two events are independent if the occurrence of event \\(B\\) provides no information about the occurrence of event \\(A\\):\n\\[\nP(A|B) = P(A)\n\\]\nAnother definition of independence:\n\\[\nP(A \\cap B) = P(A) P(B)\n\\]\nFor multiple events:\n\\[\nP(A_{1} \\cap A_{2} \\cap ... A_{n}) = P(A_{1}) P(A_{2}) ... P(A_{n})\n\\]",
    "crumbs": [
      "Probability",
      "Independence"
    ]
  },
  {
    "objectID": "content/probability/04-independence.html#conditioning-and-independence",
    "href": "content/probability/04-independence.html#conditioning-and-independence",
    "title": "Independence",
    "section": "Conditioning and Independence",
    "text": "Conditioning and Independence\nSuppose \\(A\\), \\(B\\), and \\(C\\) are events.  If \\(A\\) and \\(B\\) are independent, conditioning on \\(C\\) may remove that independence.  When we condition on \\(C\\), events \\(A\\) and \\(B\\) may no longer be independent.\n\n\n\n\nExercise\nThe king comes from a family of two children. What is the probability that his sibling is female \\(F\\) and not male \\(M\\)?\nLet all outcomes be equally likely.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\nSample \\ Space = \\{(FF), (FM), (MF), (MM)\\} = \\{(\\not F \\not F), (FM), (MF), (MM)\\}\n\\]\n\\[\nP(F|M) = \\frac{P(F \\cap M)}{M} = \\frac{2}{3} \\approx 0.6\\bar{6}\n\\]",
    "crumbs": [
      "Probability",
      "Independence"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html",
    "href": "content/probability/06-continuous-rv.html",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "A variable that can take any value within a range, requiring calculus to describe its probabilities. üìà",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#continuous-random-variable",
    "href": "content/probability/06-continuous-rv.html#continuous-random-variable",
    "title": "Continuous Random Variables",
    "section": "Continuous Random Variable",
    "text": "Continuous Random Variable\nA continuous random variable is a mapping \\(X\\) of all the events of a sample space to numerical values \\(x \\in \\mathbb{R}\\). \\[\nX: Event \\in Sample \\ Space \\to x \\in \\mathbb{R}\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#probability-density-function-pdf",
    "href": "content/probability/06-continuous-rv.html#probability-density-function-pdf",
    "title": "Continuous Random Variables",
    "section": "Probability Density Function (PDF)",
    "text": "Probability Density Function (PDF)\nA probability density function (PDF) is a mapping of values \\(x\\) of intervals of continuous random variables \\(X\\) to probabilities \\([0,1]\\).\n\\[\nP(a \\leq X \\leq b) = \\int_{a}^{b} f_{X}(x) \\ dx\n\\]\nPDF has properties: \\[\nf_{X}(x) \\geq 0, \\ \\int_{-\\infty}^{\\infty} f_{X}(x) \\ dx = 1\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#cumulative-distribution-function-cdf",
    "href": "content/probability/06-continuous-rv.html#cumulative-distribution-function-cdf",
    "title": "Continuous Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nThe cumulative distribution function (CDF) for continuous random variables is defined as:\n\\[ F_{X}(x) = P(X \\leq x) = \\int_{-\\infty}^{x} f_{X}(u) \\ du \\]\nRelation to PDF:\n\\[\nf_{X}(x) = \\frac{dF_{X}(x)}{dx}\n\\] \\[\nF_{X}(x) = \\int_{-\\infty}^{x} f_{X}(u) \\ du\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#illustration-pdf-and-cdf",
    "href": "content/probability/06-continuous-rv.html#illustration-pdf-and-cdf",
    "title": "Continuous Random Variables",
    "section": "Illustration: PDF and CDF",
    "text": "Illustration: PDF and CDF",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#expectation-and-variance-of-pdfs",
    "href": "content/probability/06-continuous-rv.html#expectation-and-variance-of-pdfs",
    "title": "Continuous Random Variables",
    "section": "Expectation and Variance of PDFs",
    "text": "Expectation and Variance of PDFs\nContinuous expectation, or mean, is the average numerical value that the continuous random variable takes over the PDF. \\[\nE[X] = \\int_{-\\infty}^{\\infty} x \\ f_{X}(x) dx\n\\]\nContinuous variance is the expected squared difference from the mean of a PDF. \\[\n\\text{Var}[X] = E[(X - E[X])^{2}] = \\int_{-\\infty}^{\\infty} (x - E[X])^2 \\ f_{X}(x) dx\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#joint-and-marginal-pdfs",
    "href": "content/probability/06-continuous-rv.html#joint-and-marginal-pdfs",
    "title": "Continuous Random Variables",
    "section": "Joint and Marginal PDFs",
    "text": "Joint and Marginal PDFs\nThe joint PDF calculates the intersection of two continuous random variables: \\[\nP((X,Y) \\in A) = \\int \\int_{A} f_{X,Y}(x_{1}, x_{2}) dx_{1} \\ dx_{2}\n\\]\nFrom the previous definition we can also compute the marginal PDF for a particular random variable:\n\\[\nf_{X}(x_{1}) = \\int_{-\\infty}^{\\infty} f_{X,Y}(x_{1}, x_{2}) dx_{2}\n\\]\n\\[\nf_{Y}(x_{2}) = \\int_{-\\infty}^{\\infty} f_{X,Y}(x_{1},x_{2}) dx_{1}\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#conditional-expectation-of-pdfs",
    "href": "content/probability/06-continuous-rv.html#conditional-expectation-of-pdfs",
    "title": "Continuous Random Variables",
    "section": "Conditional Expectation of PDFs",
    "text": "Conditional Expectation of PDFs\nThe conditional PDF gives the probability distribution of a continuous random variable given that another variable has a specific value. \\[\nf_{X|Y}(x_{1}| x_{2}) = \\frac{f_{X,Y}(x_{1}, x_{2})}{f_{Y}(x_{2})}\n\\]\nThe conditional expectation is the expected value of a continuous random variable given that another variable is fixed at a specific value. \\[\n\\mathbb{E}[X| Y = x_{2}] = \\int_{x_{1} \\in X} x_{1} \\frac{f_{X,Y}(x_{1}, x_{2})}{f_{Y}(x_{2})} dx_{1}\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  },
  {
    "objectID": "content/probability/06-continuous-rv.html#independence",
    "href": "content/probability/06-continuous-rv.html#independence",
    "title": "Continuous Random Variables",
    "section": "Independence",
    "text": "Independence\nTwo continuous random variables are independent if: \\[\nf_{X,Y}(x_{1}, x_{2}) = f_{X}(x_{1}) f_{Y}(x_{2})\n\\]\nThis can be extended to multiple random variables: \\[\nf_{X_{1},...,X{n}}(x_{1}, ..., x_{n}) = f_{X_{1}}(x_{1}) ... \\ f_{X_{n}}(x_{n})\n\\]",
    "crumbs": [
      "Probability",
      "Continuous Random Variables"
    ]
  }
]